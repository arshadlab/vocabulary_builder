{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9c556-ce9b-46aa-8869-d7c5aab69964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee827df-8f15-4cb4-85fe-e2eaca3ef27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif __name__ == \"__main__\":\\n    try:\\n        main()\\n    except Exception as e:\\n        import traceback\\n\\n        traceback.print_exc()\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\"\"\"\n",
    "python 3.8\n",
    "This script extracts NOT common words from provided source.  Intended users are \n",
    "Source can be a text file, pdf file or a URL.  Two output files are generated.\n",
    "An HTML file and a plain text file.  HTML file contains word with meaning and link to more detail explaination.\n",
    "\n",
    "Note:\n",
    "excluded_word.txt include list of words to exclude.\n",
    "Run 'pip install -r requirements.txt' to install dependencies\n",
    "\n",
    "Usage: python word_extractor.py -s <file/url> -t [minimum word length] -o [output file name]\n",
    "\n",
    "-s <file/pdf/url>\n",
    "-t Minimum word length to consier (optional, default 3)\n",
    "-o output filename base (optional, default result)\n",
    "\n",
    "Examples:\n",
    "   python word_extractor.py -s Meet_Joe_Black.srt \n",
    "\n",
    "author: <arshadm78 @ yahoo.com>\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import PyPDF2\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import argparse\n",
    "from urllib.parse import urlparse\n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True, raise_on_error=True)\n",
    "nltk.download(\"wordnet\", quiet=True, raise_on_error=True)\n",
    "nltk.download(\"words\", quiet=True, raise_on_error=True)\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def uri_validator(x):\n",
    "    try:\n",
    "        result = urlparse(x)\n",
    "        return all([result.scheme, result.netloc])\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def gettextfromurl(url):\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    words = []\n",
    "    # Extract words\n",
    "    for text in soup.stripped_strings:\n",
    "        words.extend(text.lower().split())\n",
    "    return words\n",
    "\n",
    "\n",
    "def gettextfrompdf(file):\n",
    "    \n",
    "    # Open the PDF file\n",
    "    pdf_file = open(file, \"rb\")\n",
    "\n",
    "    # Create a PDF reader object\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "    # Get the number of pages in the PDF file\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "    words = []\n",
    "    # Loop through each page and extract the text\n",
    "    for page in range(num_pages):\n",
    "        # Get the page object\n",
    "        pdf_page = pdf_reader.pages[page]\n",
    "\n",
    "        # Extract the text from the page\n",
    "        page_text = pdf_page.extract_text().lower()\n",
    "\n",
    "        # Split the text into words\n",
    "        words += page_text.split()\n",
    "\n",
    "    # Close the PDF file\n",
    "    pdf_file.close()\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "def gettext(file):\n",
    "    \n",
    "    text_file = open(file, \"r\")\n",
    "    text = text_file.read().lower().replace(\".\", \"\").replace(\"--\", \"\")\n",
    "    \n",
    "    pattern = \"[a-zA-Z\\-\\.'/]+\"\n",
    "    words = re.findall(pattern, text)\n",
    "    \n",
    "    text_file.close()\n",
    "    return words\n",
    "\n",
    "\n",
    "def getFinalList(text_list, min_length=3):\n",
    "    wordnet_tag = [\"n\", \"s\", \"a\", \"r\", \"v\"]\n",
    "    \n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    "    with open(\"excluded_word.txt\", \"r\") as f_object:\n",
    "        common_words = f_object.read().split()\n",
    "        \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    full_list = words.words()\n",
    "    \n",
    "    # traverse for all elements\n",
    "    lem_tmp = []\n",
    "    for x in text_list:\n",
    "        lem = x\n",
    "\n",
    "        for t in wordnet_tag:\n",
    "            lem1 = wnl.lemmatize(x, t)\n",
    "            # Use shortest form\n",
    "            if lem1 != x:\n",
    "                lem = lem1\n",
    "\n",
    "        # check if exists in unique_list or not\n",
    "        if len(lem) > min_length and lem.isalpha():\n",
    "            if lem not in common_words and lem not in stop_words and lem in full_list:\n",
    "                # if x != lem:\n",
    "                #    final_word = x + \" [\" + lem + \"]\"\n",
    "                # else:\n",
    "                final_word = lem\n",
    "                if final_word not in unique_list:\n",
    "                    unique_list.append(final_word)\n",
    "\n",
    "    return unique_list\n",
    "\n",
    "def getFinalList_withcount(text_list, min_length=3, word_count={}):\n",
    "    wordnet_tag = [\"n\", \"s\", \"a\", \"r\", \"v\"]\n",
    "    \n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    "    #word_count = {}\n",
    "    with open(\"excluded_word.txt\", \"r\") as f_object:\n",
    "        common_words = f_object.read().split()\n",
    "        \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    full_list = words.words()\n",
    "    \n",
    "    # traverse for all elements\n",
    "    lem_tmp = []\n",
    "    for x in text_list:\n",
    "        lem = x\n",
    "\n",
    "        for t in wordnet_tag:\n",
    "            lem1 = wnl.lemmatize(x, t)\n",
    "            # Use shortest form\n",
    "            if lem1 != x:\n",
    "                lem = lem1\n",
    "\n",
    "        # check if exists in unique_list or not\n",
    "        if len(lem) > min_length and lem.isalpha():\n",
    "            if lem not in common_words and lem not in stop_words and lem in full_list:\n",
    "                # if x != lem:\n",
    "                #    final_word = x + \" [\" + lem + \"]\"\n",
    "                # else:\n",
    "                final_word = lem\n",
    "                if final_word in word_count:\n",
    "                    word_count[final_word] += 1\n",
    "                else:\n",
    "                    word_count[final_word] = 1\n",
    "    \n",
    "    sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "def main1(args=None):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-s\", \"--source\", help=\"Input source. text, pdf or url\", default='/home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E07.720p.WEB-DL.x264.350MB-PaHe.in.srt', type=str\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-t\", \"--threshold\", help=\"Minimum word size to consider\", default=3, type=int\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        help=\"Output files base name\",\n",
    "        default=\"result\",\n",
    "        required=False,\n",
    "        type=str,\n",
    "    )\n",
    "    \n",
    "    arg_list = parser.parse_args()\n",
    "    print(f\"Processing...\")\n",
    "    word_lst = []\n",
    "    if uri_validator(arg_list.source):\n",
    "        word_lst = gettextfromurl(arg_list.source)\n",
    "    elif arg_list.source.endswith(\".pdf\"):\n",
    "        word_lst = gettextfrompdf(arg_list.source)\n",
    "    else:\n",
    "        word_lst = gettext(arg_list.source)\n",
    "\n",
    "    final_list = getFinalList(word_lst, arg_list.threshold)\n",
    "\n",
    "    # Define the initial HTML content\n",
    "    html_content = \"<html><head></head><body>\"\n",
    "    html_content += f\"<h1>Source: {arg_list.source}</h1>\"\n",
    "  \n",
    "    count = 1\n",
    "    for word in final_list:\n",
    "        wnl.lemmatize(word, \"v\")\n",
    "        synsets = wn.synsets(word)\n",
    "        if len(synsets) == 0:\n",
    "            continue\n",
    "        html_content += f\"<h2>{count} - <a href='https://www.merriam-webster.com/dictionary/{word}'>{word.capitalize()}</a> </h2>\"\n",
    "        html_content += \"<ul>\"\n",
    "        for synset in synsets:\n",
    "            html_content += \"<ul>\"\n",
    "            # for definition in synset.definition():\n",
    "            html_content += f\"<li>{synset.definition().capitalize()}</li>\"\n",
    "            for example in synset.examples():\n",
    "                html_content += \"<br>   '\" + example.capitalize() + \"'</br>\"\n",
    "            html_content += \"<br></br></ul>\"\n",
    "        html_content += f\"<a href='https://www.google.com/search?tbm=isch&q={word}'> Image search </a></ul>\"\n",
    "        count += 1\n",
    "    html_content += \"</body></html>\"\n",
    "    # Write the HTML content to a new file\n",
    "    with open(arg_list.output + \".html\", \"w\") as f:\n",
    "        f.write(html_content)\n",
    "        f.close()\n",
    "\n",
    "    with open(arg_list.output + \".txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(final_list))\n",
    "        f.close()\n",
    "        \n",
    "    print(f\"HTML written to {arg_list.output}.html\")\n",
    "    print(f\"Words written to {arg_list.output}.txt\")\n",
    "\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "195cb7ba-a6ff-4699-830c-84a32d6aaeb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'basement'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m word_lst \u001b[38;5;241m=\u001b[39m gettext(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E07.720p.WEB-DL.x264.350MB-PaHe.in.srt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgetFinalList1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_lst\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 170\u001b[0m, in \u001b[0;36mgetFinalList1\u001b[0;34m(text_list, min_length)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 word_count[final_word] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    169\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m                 word_count[final_word] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m word_count\n",
      "\u001b[0;31mKeyError\u001b[0m: 'basement'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0856f59-f33a-4b0a-aaca-a442fd4cadb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E09.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E16.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E03.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E23.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E02.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E15.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E07.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E13.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E19.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E18.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E04.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E21.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E17.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S03E01.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E06.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E08.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E22.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E20.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E10.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E11.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E14.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E05.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E01.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Processing /home/arshad/Downloads/mentalist_sub/The.Mentalist.S02E12.720p.WEB-DL.x264.350MB-PaHe.in.srt\n",
      "Word count: 1458\n",
      "weird: 20\n",
      "warrant: 20\n",
      "psychic: 19\n",
      "sloop: 18\n",
      "ahem: 16\n",
      "nash: 15\n",
      "vulture: 15\n",
      "flask: 14\n",
      "saint: 14\n",
      "blah: 14\n",
      "alibi: 13\n",
      "bust: 13\n",
      "assault: 13\n",
      "stile: 13\n",
      "bertram: 12\n",
      "carter: 12\n",
      "carl: 11\n",
      "cliff: 11\n",
      "ricin: 11\n",
      "hopper: 11\n",
      "reunion: 11\n",
      "abigail: 10\n",
      "rancho: 10\n",
      "bunt: 10\n",
      "bret: 10\n",
      "yell: 9\n",
      "landau: 9\n",
      "ward: 8\n",
      "hunch: 8\n",
      "jerk: 8\n",
      "buck: 8\n",
      "corpse: 8\n",
      "narcotic: 8\n",
      "whoo: 8\n",
      "lynch: 8\n",
      "reed: 8\n",
      "drill: 7\n",
      "trash: 7\n",
      "sake: 7\n",
      "stab: 7\n",
      "truffle: 7\n",
      "castor: 7\n",
      "sparhawk: 7\n",
      "marc: 7\n",
      "resent: 6\n",
      "absurd: 6\n",
      "shrink: 6\n",
      "inmate: 6\n",
      "hush: 6\n",
      "sparrow: 6\n",
      "ludo: 6\n",
      "drab: 6\n",
      "rifle: 6\n",
      "dooley: 6\n",
      "prank: 6\n",
      "perceptive: 5\n",
      "thieve: 5\n",
      "dose: 5\n",
      "palm: 5\n",
      "lieutenant: 5\n",
      "polygraph: 5\n",
      "relieve: 5\n",
      "alley: 5\n",
      "bingo: 5\n",
      "behold: 5\n",
      "notch: 5\n",
      "barge: 5\n",
      "grieve: 5\n",
      "stunt: 5\n",
      "cartel: 5\n",
      "vest: 5\n",
      "piss: 5\n",
      "grudge: 5\n",
      "sinner: 5\n",
      "pawn: 5\n",
      "bleed: 5\n",
      "glitter: 5\n",
      "tara: 5\n",
      "unicorn: 5\n",
      "brock: 5\n",
      "fisher: 5\n",
      "riddle: 5\n",
      "bodhi: 5\n",
      "starve: 4\n",
      "ballistics: 4\n",
      "sadist: 4\n",
      "griffin: 4\n",
      "antidote: 4\n",
      "scout: 4\n",
      "conscience: 4\n",
      "inspector: 4\n",
      "stroll: 4\n",
      "trance: 4\n",
      "lure: 4\n",
      "ruth: 4\n",
      "hustle: 4\n",
      "fuss: 4\n",
      "snap: 4\n",
      "immortal: 4\n",
      "couch: 4\n",
      "sober: 4\n",
      "boom: 4\n",
      "skull: 4\n",
      "hank: 4\n",
      "amnesia: 4\n",
      "rash: 4\n",
      "dizzy: 4\n",
      "compel: 4\n",
      "driveway: 4\n",
      "pier: 4\n",
      "stripper: 4\n",
      "wither: 4\n",
      "haunt: 4\n",
      "wretch: 4\n",
      "coalition: 4\n",
      "bang: 4\n",
      "razor: 4\n",
      "salter: 4\n",
      "actuality: 4\n",
      "injustice: 3\n",
      "resentment: 3\n",
      "crook: 3\n",
      "shady: 3\n",
      "sneak: 3\n",
      "compliment: 3\n",
      "stall: 3\n",
      "apprise: 3\n",
      "adrenaline: 3\n",
      "ghoulish: 3\n",
      "glare: 3\n",
      "restrain: 3\n",
      "stomp: 3\n",
      "halfway: 3\n",
      "hoax: 3\n",
      "ruse: 3\n",
      "bogus: 3\n",
      "stash: 3\n",
      "creepy: 3\n",
      "stag: 3\n",
      "sacrament: 3\n",
      "sacred: 3\n",
      "tragedy: 3\n",
      "butt: 3\n",
      "estrange: 3\n",
      "memento: 3\n",
      "leniency: 3\n",
      "grumpy: 3\n",
      "blindfold: 3\n",
      "interference: 3\n",
      "snoop: 3\n",
      "misdirect: 3\n",
      "fracture: 3\n",
      "cunning: 3\n",
      "charlatan: 3\n",
      "leverage: 3\n",
      "bailiff: 3\n",
      "stake: 3\n",
      "bump: 3\n",
      "penalty: 3\n",
      "straw: 3\n",
      "penal: 3\n",
      "fascinate: 3\n",
      "frustration: 3\n",
      "silverwing: 3\n",
      "bolo: 3\n",
      "illicit: 3\n",
      "poke: 3\n",
      "impulsive: 3\n",
      "slack: 3\n",
      "chill: 3\n",
      "ongoing: 3\n",
      "knight: 3\n",
      "bing: 3\n",
      "rook: 3\n",
      "felony: 3\n",
      "prop: 3\n",
      "eureka: 3\n",
      "lobbyist: 3\n",
      "alleyway: 3\n",
      "codefendant: 3\n",
      "bruise: 3\n",
      "presume: 3\n",
      "morphine: 3\n",
      "burnside: 3\n",
      "goon: 3\n",
      "novella: 3\n",
      "hallway: 3\n",
      "hogwash: 3\n",
      "pitcher: 3\n",
      "fitch: 3\n",
      "malarkey: 3\n",
      "ouch: 3\n",
      "tumor: 3\n",
      "stun: 3\n",
      "brawl: 3\n",
      "banger: 3\n",
      "cedar: 3\n",
      "aura: 3\n",
      "bullfrog: 3\n",
      "developer: 3\n",
      "raft: 3\n",
      "activist: 3\n",
      "sponsor: 2\n",
      "hopefully: 2\n",
      "corny: 2\n",
      "recede: 2\n",
      "lavish: 2\n",
      "labor: 2\n",
      "zoom: 2\n",
      "specialty: 2\n",
      "perpetrator: 2\n",
      "provisional: 2\n",
      "implicate: 2\n",
      "dime: 2\n",
      "clinic: 2\n",
      "induce: 2\n",
      "coma: 2\n",
      "compress: 2\n",
      "carbon: 2\n",
      "tempt: 2\n",
      "inspect: 2\n",
      "dean: 2\n",
      "outbreak: 2\n",
      "protocol: 2\n",
      "plague: 2\n",
      "cobra: 2\n",
      "tragic: 2\n",
      "compound: 2\n",
      "oversee: 2\n",
      "weep: 2\n",
      "decontamination: 2\n",
      "denial: 2\n",
      "orphan: 2\n",
      "foul: 2\n",
      "grief: 2\n",
      "intense: 2\n",
      "scanner: 2\n",
      "supplicant: 2\n",
      "gesture: 2\n",
      "germ: 2\n",
      "breakdown: 2\n",
      "salient: 2\n",
      "whore: 2\n",
      "anonymous: 2\n",
      "menace: 2\n",
      "canada: 2\n",
      "nutty: 2\n",
      "culvert: 2\n",
      "northeast: 2\n",
      "asylum: 2\n",
      "unstable: 2\n",
      "mercy: 2\n",
      "gambit: 2\n",
      "cathartic: 2\n",
      "matrix: 2\n",
      "treasury: 2\n",
      "chilly: 2\n",
      "testify: 2\n",
      "abusive: 2\n",
      "eyebrow: 2\n",
      "rapist: 2\n",
      "pelican: 2\n",
      "exemplary: 2\n",
      "provider: 2\n",
      "traumatic: 2\n",
      "utility: 2\n",
      "blackout: 2\n",
      "blot: 2\n",
      "comeback: 2\n",
      "misery: 2\n",
      "monster: 2\n",
      "surrender: 2\n",
      "discredit: 2\n",
      "testimony: 2\n",
      "fathom: 2\n",
      "server: 2\n",
      "uncanny: 2\n",
      "objection: 2\n",
      "modest: 2\n",
      "semester: 2\n",
      "criminology: 2\n",
      "redemption: 2\n",
      "dismay: 2\n",
      "obligation: 2\n",
      "alternate: 2\n",
      "pursuit: 2\n",
      "slasher: 2\n",
      "reflection: 2\n",
      "reflexology: 2\n",
      "obsess: 2\n",
      "divvy: 2\n",
      "debatable: 2\n",
      "pious: 2\n",
      "regardless: 2\n",
      "tolerate: 2\n",
      "jumper: 2\n",
      "splat: 2\n",
      "aide: 2\n",
      "methodical: 2\n",
      "fortunately: 2\n",
      "pathology: 2\n",
      "drift: 2\n",
      "hound: 2\n",
      "ballerina: 2\n",
      "stepdaughter: 2\n",
      "stepbrother: 2\n",
      "filter: 2\n",
      "flatter: 2\n",
      "adultery: 2\n",
      "arraign: 2\n",
      "accost: 2\n",
      "startle: 2\n",
      "overhear: 2\n",
      "accessory: 2\n",
      "sham: 2\n",
      "westing: 2\n",
      "shove: 2\n",
      "pretentious: 2\n",
      "comrade: 2\n",
      "inquiry: 2\n",
      "egotistical: 2\n",
      "vanish: 2\n",
      "intruder: 2\n",
      "relapse: 2\n",
      "negotiate: 2\n",
      "extortion: 2\n",
      "prep: 2\n",
      "chalk: 2\n",
      "bash: 2\n",
      "stray: 2\n",
      "medication: 2\n",
      "garlic: 2\n",
      "recipe: 2\n",
      "malice: 2\n",
      "horrify: 2\n",
      "whoop: 2\n",
      "squash: 2\n",
      "mistress: 2\n",
      "headline: 2\n",
      "execution: 2\n",
      "blanket: 2\n",
      "irrelevant: 2\n",
      "wack: 2\n",
      "squatter: 2\n",
      "snoopy: 2\n",
      "barely: 2\n",
      "jack: 2\n",
      "prowess: 2\n",
      "impulse: 2\n",
      "juvenile: 2\n",
      "spook: 2\n",
      "fascist: 2\n",
      "twitch: 2\n",
      "transmitter: 2\n",
      "nanny: 2\n",
      "tracker: 2\n",
      "torture: 2\n",
      "tequila: 2\n",
      "wagon: 2\n",
      "stem: 2\n",
      "contusion: 2\n",
      "retail: 2\n",
      "cute: 2\n",
      "seethe: 2\n",
      "primal: 2\n",
      "hostility: 2\n",
      "tense: 2\n",
      "squat: 2\n",
      "smuggler: 2\n",
      "swimsuit: 2\n",
      "specie: 2\n",
      "merchandise: 2\n",
      "psyche: 2\n",
      "fresno: 2\n",
      "plead: 2\n",
      "quackery: 2\n",
      "vouch: 2\n",
      "pedal: 2\n",
      "ding: 2\n",
      "stipple: 2\n",
      "remodel: 2\n",
      "deterrent: 2\n",
      "productive: 2\n",
      "smuggle: 2\n",
      "tarp: 2\n",
      "psychopath: 2\n",
      "muffin: 2\n",
      "ditch: 2\n",
      "torque: 2\n",
      "dread: 2\n",
      "amendment: 2\n",
      "mockery: 2\n",
      "jeopardy: 2\n",
      "lair: 2\n",
      "hanky: 2\n",
      "dock: 2\n",
      "mistrial: 2\n",
      "contempt: 2\n",
      "tweak: 2\n",
      "latitude: 2\n",
      "prejudice: 2\n",
      "drip: 2\n",
      "native: 2\n",
      "rage: 2\n",
      "ranger: 2\n",
      "weed: 2\n",
      "lame: 2\n",
      "bonnet: 2\n",
      "hippy: 2\n",
      "barrel: 2\n",
      "parch: 2\n",
      "frustrate: 2\n",
      "bolt: 2\n",
      "bulletproof: 2\n",
      "intimidate: 2\n",
      "empathy: 2\n",
      "chaos: 2\n",
      "brigade: 2\n",
      "registration: 2\n",
      "allegedly: 2\n",
      "vandalism: 2\n",
      "sloppy: 2\n",
      "stink: 2\n",
      "trespass: 2\n",
      "instructor: 2\n",
      "zeta: 2\n",
      "quirk: 2\n",
      "caliber: 2\n",
      "junk: 2\n",
      "wager: 2\n",
      "degenerate: 2\n",
      "crude: 2\n",
      "choke: 2\n",
      "wuss: 2\n",
      "butterfly: 2\n",
      "arson: 2\n",
      "facial: 2\n",
      "pyramid: 2\n",
      "depict: 2\n",
      "mythology: 2\n",
      "glottal: 2\n",
      "pristine: 2\n",
      "antiquity: 2\n",
      "likewise: 2\n",
      "pending: 2\n",
      "peter: 2\n",
      "intrude: 2\n",
      "dibs: 2\n",
      "misspell: 2\n",
      "gale: 2\n",
      "pretense: 2\n",
      "betrayal: 2\n",
      "welder: 2\n",
      "eavesdrop: 2\n",
      "vermin: 2\n",
      "bunk: 2\n",
      "discreetly: 2\n",
      "corp: 2\n",
      "considerate: 2\n",
      "cemetery: 2\n",
      "lilac: 2\n",
      "pulse: 2\n",
      "janitor: 2\n",
      "breach: 2\n",
      "heroin: 2\n",
      "idiotic: 2\n",
      "vicious: 2\n",
      "barrette: 2\n",
      "balloon: 2\n",
      "spooky: 2\n",
      "scotch: 2\n",
      "cynicism: 2\n",
      "psychoanalyst: 2\n",
      "infidelity: 2\n",
      "claret: 2\n",
      "solicit: 2\n",
      "misuse: 2\n",
      "slam: 2\n",
      "coup: 2\n",
      "bigwig: 2\n",
      "scoop: 2\n",
      "cult: 2\n",
      "nasty: 2\n",
      "forgery: 2\n",
      "untethered: 2\n",
      "sole: 2\n",
      "stooge: 2\n",
      "evasive: 2\n",
      "touchdown: 2\n",
      "rebel: 2\n",
      "unsettle: 2\n",
      "caller: 2\n",
      "beech: 2\n",
      "inappropriate: 2\n",
      "greed: 2\n",
      "forth: 2\n",
      "allegiance: 2\n",
      "integrate: 2\n",
      "mercer: 2\n",
      "aspirin: 2\n",
      "crackpot: 2\n",
      "cocaine: 2\n",
      "harassment: 2\n",
      "mend: 2\n",
      "conscientious: 2\n",
      "clover: 2\n",
      "bootlegger: 2\n",
      "strawberry: 2\n",
      "invisible: 2\n",
      "doughnut: 2\n",
      "legion: 2\n",
      "herring: 2\n",
      "captivate: 2\n",
      "mountainside: 1\n",
      "bide: 1\n",
      "magician: 1\n",
      "regal: 1\n",
      "execute: 1\n",
      "champagne: 1\n",
      "legible: 1\n",
      "vault: 1\n",
      "godsend: 1\n",
      "safecracking: 1\n",
      "beater: 1\n",
      "forecourt: 1\n",
      "jean: 1\n",
      "aviator: 1\n",
      "bulldog: 1\n",
      "starlite: 1\n",
      "partially: 1\n",
      "jersey: 1\n",
      "alimony: 1\n",
      "sedation: 1\n",
      "incarceration: 1\n",
      "goblin: 1\n",
      "superficially: 1\n",
      "extrapolate: 1\n",
      "enhance: 1\n",
      "darn: 1\n",
      "intestine: 1\n",
      "supposition: 1\n",
      "windward: 1\n",
      "ratio: 1\n",
      "downer: 1\n",
      "sacrosanct: 1\n",
      "roster: 1\n",
      "dicky: 1\n",
      "brat: 1\n",
      "nickel: 1\n",
      "fern: 1\n",
      "geology: 1\n",
      "integrity: 1\n",
      "zing: 1\n",
      "vicinity: 1\n",
      "criminality: 1\n",
      "anthrax: 1\n",
      "botulism: 1\n",
      "bubonic: 1\n",
      "cardiac: 1\n",
      "suffocation: 1\n",
      "distinct: 1\n",
      "enzyme: 1\n",
      "precaution: 1\n",
      "biometric: 1\n",
      "unavoidable: 1\n",
      "jade: 1\n",
      "originality: 1\n",
      "eric: 1\n",
      "fidelity: 1\n",
      "presently: 1\n",
      "eloquent: 1\n",
      "pickle: 1\n",
      "wail: 1\n",
      "calculus: 1\n",
      "eventuality: 1\n",
      "irradiate: 1\n",
      "certainty: 1\n",
      "biochemistry: 1\n",
      "abruptly: 1\n",
      "retract: 1\n",
      "mettle: 1\n",
      "vend: 1\n",
      "astrophysics: 1\n",
      "wipe: 1\n",
      "hood: 1\n",
      "motif: 1\n",
      "copacetic: 1\n",
      "subsequently: 1\n",
      "reassure: 1\n",
      "radius: 1\n",
      "beaker: 1\n",
      "incendiary: 1\n",
      "tommy: 1\n",
      "incoherent: 1\n",
      "succinct: 1\n",
      "disregard: 1\n",
      "firstly: 1\n",
      "precision: 1\n",
      "forbearance: 1\n",
      "siphon: 1\n",
      "phew: 1\n",
      "tinder: 1\n",
      "claw: 1\n",
      "laud: 1\n",
      "vendetta: 1\n",
      "clog: 1\n",
      "reattach: 1\n",
      "moody: 1\n",
      "incorporate: 1\n",
      "arcade: 1\n",
      "ringman: 1\n",
      "retest: 1\n",
      "asterisk: 1\n",
      "quicksand: 1\n",
      "impertinent: 1\n",
      "nosy: 1\n",
      "constraint: 1\n",
      "acquit: 1\n",
      "poly: 1\n",
      "tray: 1\n",
      "retake: 1\n",
      "shield: 1\n",
      "molester: 1\n",
      "unblock: 1\n",
      "interfere: 1\n",
      "salute: 1\n",
      "tenant: 1\n",
      "rewind: 1\n",
      "medicate: 1\n",
      "cayman: 1\n",
      "relive: 1\n",
      "crumbly: 1\n",
      "reek: 1\n",
      "filthy: 1\n",
      "fade: 1\n",
      "imagery: 1\n",
      "lapse: 1\n",
      "lunatic: 1\n",
      "crimson: 1\n",
      "rally: 1\n",
      "ferocious: 1\n",
      "ectoplasm: 1\n",
      "ticktock: 1\n",
      "vessel: 1\n",
      "commodity: 1\n",
      "eerie: 1\n",
      "lethally: 1\n",
      "inject: 1\n",
      "cannibal: 1\n",
      "voyeur: 1\n",
      "resonate: 1\n",
      "synchronize: 1\n",
      "franklin: 1\n",
      "shrine: 1\n",
      "likelihood: 1\n",
      "belay: 1\n",
      "riverside: 1\n",
      "psych: 1\n",
      "evaluation: 1\n",
      "corona: 1\n",
      "mill: 1\n",
      "sacrifice: 1\n",
      "smack: 1\n",
      "bumptious: 1\n",
      "concubine: 1\n",
      "patronize: 1\n",
      "haul: 1\n",
      "legislator: 1\n",
      "traumatize: 1\n",
      "wrench: 1\n",
      "basset: 1\n",
      "immature: 1\n",
      "figurine: 1\n",
      "unfiltered: 1\n",
      "windbag: 1\n",
      "narcissistic: 1\n",
      "impressionable: 1\n",
      "accordingly: 1\n",
      "fluke: 1\n",
      "ransack: 1\n",
      "investigator: 1\n",
      "spit: 1\n",
      "seduce: 1\n",
      "trashy: 1\n",
      "fling: 1\n",
      "strumpet: 1\n",
      "noose: 1\n",
      "vastness: 1\n",
      "subvert: 1\n",
      "commend: 1\n",
      "passionate: 1\n",
      "articulate: 1\n",
      "linear: 1\n",
      "incise: 1\n",
      "superficial: 1\n",
      "anterior: 1\n",
      "schilling: 1\n",
      "acclaim: 1\n",
      "mousse: 1\n",
      "petite: 1\n",
      "chive: 1\n",
      "sheer: 1\n",
      "bundle: 1\n",
      "replacement: 1\n",
      "scrapper: 1\n",
      "fist: 1\n",
      "cheeky: 1\n",
      "huddle: 1\n",
      "preliminary: 1\n",
      "ingest: 1\n",
      "pudding: 1\n",
      "manipulative: 1\n",
      "fate: 1\n",
      "breakup: 1\n",
      "occupational: 1\n",
      "elevate: 1\n",
      "ransacker: 1\n",
      "erratically: 1\n",
      "applause: 1\n",
      "monsieur: 1\n",
      "afloat: 1\n",
      "modesty: 1\n",
      "perfection: 1\n",
      "bounce: 1\n",
      "groundless: 1\n",
      "racketeer: 1\n",
      "sprinkle: 1\n",
      "mite: 1\n",
      "peckish: 1\n",
      "talented: 1\n",
      "investor: 1\n",
      "frosty: 1\n",
      "sinister: 1\n",
      "deadbeat: 1\n",
      "thaw: 1\n",
      "ghoul: 1\n",
      "testament: 1\n",
      "appetite: 1\n",
      "tart: 1\n",
      "flavor: 1\n",
      "sublimate: 1\n",
      "aggression: 1\n",
      "roger: 1\n",
      "snippy: 1\n",
      "livid: 1\n",
      "sage: 1\n",
      "coriander: 1\n",
      "inherit: 1\n",
      "accentuate: 1\n",
      "sleek: 1\n",
      "trim: 1\n",
      "pregnancy: 1\n",
      "impend: 1\n",
      "fatherhood: 1\n",
      "elephant: 1\n",
      "fiscally: 1\n",
      "circumstantial: 1\n",
      "serviette: 1\n",
      "culinary: 1\n",
      "parma: 1\n",
      "mint: 1\n",
      "basil: 1\n",
      "reinterpretation: 1\n",
      "overpower: 1\n",
      "sabotage: 1\n",
      "batch: 1\n",
      "carve: 1\n",
      "harsh: 1\n",
      "glib: 1\n",
      "heiress: 1\n",
      "hail: 1\n",
      "eerily: 1\n",
      "stumble: 1\n",
      "reframe: 1\n",
      "weaver: 1\n",
      "lumber: 1\n",
      "pacific: 1\n",
      "casually: 1\n",
      "smelly: 1\n",
      "cherub: 1\n",
      "rout: 1\n",
      "comply: 1\n",
      "snack: 1\n",
      "refreshment: 1\n",
      "veracity: 1\n",
      "weasel: 1\n",
      "shrivel: 1\n",
      "transcript: 1\n",
      "consolation: 1\n",
      "ringleader: 1\n",
      "skittish: 1\n",
      "resilient: 1\n",
      "brag: 1\n",
      "showy: 1\n",
      "lighten: 1\n",
      "professionalism: 1\n",
      "schoolboy: 1\n",
      "insure: 1\n",
      "idiocy: 1\n",
      "resurrect: 1\n",
      "unabridged: 1\n",
      "stern: 1\n",
      "brad: 1\n",
      "gladiator: 1\n",
      "mistrust: 1\n",
      "bluff: 1\n",
      "titanium: 1\n",
      "malinger: 1\n",
      "demeanor: 1\n",
      "loft: 1\n",
      "dollop: 1\n",
      "tingle: 1\n",
      "breadwinner: 1\n",
      "egomaniac: 1\n",
      "dispense: 1\n",
      "resentful: 1\n",
      "craven: 1\n",
      "auction: 1\n",
      "deck: 1\n",
      "proposition: 1\n",
      "mystical: 1\n",
      "wive: 1\n",
      "unattached: 1\n",
      "intensity: 1\n",
      "jake: 1\n",
      "energetic: 1\n",
      "waterfront: 1\n",
      "autopsy: 1\n",
      "pavement: 1\n",
      "abrasion: 1\n",
      "seminar: 1\n",
      "dominance: 1\n",
      "customary: 1\n",
      "bare: 1\n",
      "canine: 1\n",
      "genitals: 1\n",
      "reheat: 1\n",
      "reconcile: 1\n",
      "hurrah: 1\n",
      "zenith: 1\n",
      "dope: 1\n",
      "ostentation: 1\n",
      "inundate: 1\n",
      "ahoy: 1\n",
      "vain: 1\n",
      "ruthless: 1\n",
      "frostbite: 1\n",
      "bumper: 1\n",
      "standoff: 1\n",
      "metaphorically: 1\n",
      "selfishness: 1\n",
      "homo: 1\n",
      "subtlety: 1\n",
      "parlor: 1\n",
      "liable: 1\n",
      "shifter: 1\n",
      "gauche: 1\n",
      "symbolize: 1\n",
      "lust: 1\n",
      "squeamish: 1\n",
      "earner: 1\n",
      "sympathize: 1\n",
      "soulful: 1\n",
      "wreck: 1\n",
      "napa: 1\n",
      "tangle: 1\n",
      "brim: 1\n",
      "tiffany: 1\n",
      "continuance: 1\n",
      "consumption: 1\n",
      "lotto: 1\n",
      "senile: 1\n",
      "chad: 1\n",
      "saddle: 1\n",
      "physic: 1\n",
      "hitter: 1\n",
      "narcissist: 1\n",
      "inflammatory: 1\n",
      "prejudicial: 1\n",
      "stipulate: 1\n",
      "ludicrous: 1\n",
      "pettifoggery: 1\n",
      "tiresome: 1\n",
      "numerous: 1\n",
      "airtight: 1\n",
      "flimsy: 1\n",
      "burden: 1\n",
      "fluff: 1\n",
      "anticlimactic: 1\n",
      "baggy: 1\n",
      "lease: 1\n",
      "embezzle: 1\n",
      "hillside: 1\n",
      "poster: 1\n",
      "quake: 1\n",
      "pluck: 1\n",
      "coif: 1\n",
      "figurehead: 1\n",
      "latch: 1\n",
      "willet: 1\n",
      "shotgun: 1\n",
      "marksman: 1\n",
      "mallard: 1\n",
      "scope: 1\n",
      "sniper: 1\n",
      "craziness: 1\n",
      "disrupt: 1\n",
      "unrelated: 1\n",
      "participate: 1\n",
      "disruption: 1\n",
      "awesome: 1\n",
      "graze: 1\n",
      "wicked: 1\n",
      "retrograde: 1\n",
      "corrective: 1\n",
      "chico: 1\n",
      "clan: 1\n",
      "raccoon: 1\n",
      "rattlesnake: 1\n",
      "sharpshooter: 1\n",
      "irrigation: 1\n",
      "ambivalence: 1\n",
      "marijuana: 1\n",
      "recommendation: 1\n",
      "peddle: 1\n",
      "pastiche: 1\n",
      "interventionist: 1\n",
      "woozy: 1\n",
      "hover: 1\n",
      "rustle: 1\n",
      "interviewer: 1\n",
      "unhappiness: 1\n",
      "pine: 1\n",
      "posthypnotic: 1\n",
      "latecomer: 1\n",
      "culturally: 1\n",
      "displease: 1\n",
      "triple: 1\n",
      "jogger: 1\n",
      "wardrobe: 1\n",
      "extrovert: 1\n",
      "assailant: 1\n",
      "racket: 1\n",
      "constitutional: 1\n",
      "mobility: 1\n",
      "cain: 1\n",
      "nomad: 1\n",
      "lawyerly: 1\n",
      "advisement: 1\n",
      "whew: 1\n",
      "torment: 1\n",
      "nurture: 1\n",
      "brutish: 1\n",
      "derange: 1\n",
      "clam: 1\n",
      "decal: 1\n",
      "knickknack: 1\n",
      "loafer: 1\n",
      "chatty: 1\n",
      "affiliation: 1\n",
      "valet: 1\n",
      "stub: 1\n",
      "magnify: 1\n",
      "exceed: 1\n",
      "vandalize: 1\n",
      "falsely: 1\n",
      "eager: 1\n",
      "rick: 1\n",
      "mechanic: 1\n",
      "redo: 1\n",
      "crowbar: 1\n",
      "harass: 1\n",
      "blacken: 1\n",
      "hath: 1\n",
      "rant: 1\n",
      "cruise: 1\n",
      "disorderly: 1\n",
      "touchy: 1\n",
      "shed: 1\n",
      "conviction: 1\n",
      "conundrum: 1\n",
      "mysteriously: 1\n",
      "sarcasm: 1\n",
      "bozo: 1\n",
      "nook: 1\n",
      "exquisite: 1\n",
      "oblivious: 1\n",
      "doom: 1\n",
      "shocker: 1\n",
      "roast: 1\n",
      "deed: 1\n",
      "concede: 1\n",
      "decipher: 1\n",
      "moralist: 1\n",
      "galactic: 1\n",
      "flaky: 1\n",
      "beam: 1\n",
      "gouge: 1\n",
      "paradox: 1\n",
      "pesky: 1\n",
      "unaccounted: 1\n",
      "nougat: 1\n",
      "tidewater: 1\n",
      "concierge: 1\n",
      "delude: 1\n",
      "bunker: 1\n",
      "doohickey: 1\n",
      "scrounge: 1\n",
      "unsearched: 1\n",
      "shrewd: 1\n",
      "fiddle: 1\n",
      "residential: 1\n",
      "clout: 1\n",
      "inspection: 1\n",
      "fairy: 1\n",
      "tale: 1\n",
      "blister: 1\n",
      "callus: 1\n",
      "syndrome: 1\n",
      "restart: 1\n",
      "rosemary: 1\n",
      "muse: 1\n",
      "snapshot: 1\n",
      "afterlife: 1\n",
      "hippopotamus: 1\n",
      "sunup: 1\n",
      "muzzle: 1\n",
      "funky: 1\n",
      "swirl: 1\n",
      "cuckold: 1\n",
      "impotence: 1\n",
      "masochism: 1\n",
      "homosexuality: 1\n",
      "accustom: 1\n",
      "cranky: 1\n",
      "artifact: 1\n",
      "circa: 1\n",
      "chatter: 1\n",
      "grid: 1\n",
      "madeline: 1\n",
      "indicative: 1\n",
      "stubborn: 1\n",
      "bull: 1\n",
      "budge: 1\n",
      "premier: 1\n",
      "indict: 1\n",
      "colt: 1\n",
      "rebellious: 1\n",
      "despair: 1\n",
      "bead: 1\n",
      "willow: 1\n",
      "scenario: 1\n",
      "gallant: 1\n",
      "victor: 1\n",
      "broker: 1\n",
      "premeditation: 1\n",
      "vulnerability: 1\n",
      "rumple: 1\n",
      "gentleness: 1\n",
      "glum: 1\n",
      "chauffeur: 1\n",
      "kingmaker: 1\n",
      "await: 1\n",
      "brevity: 1\n",
      "heck: 1\n",
      "psychological: 1\n",
      "molly: 1\n",
      "scribble: 1\n",
      "stoop: 1\n",
      "hustler: 1\n",
      "unrequited: 1\n",
      "throwaway: 1\n",
      "mein: 1\n",
      "lilt: 1\n",
      "veteran: 1\n",
      "authentic: 1\n",
      "wrongdoing: 1\n",
      "extortionist: 1\n",
      "blockbuster: 1\n",
      "whatnot: 1\n",
      "directness: 1\n",
      "brace: 1\n",
      "ample: 1\n",
      "grubby: 1\n",
      "vivid: 1\n",
      "carat: 1\n",
      "slap: 1\n",
      "spat: 1\n",
      "obsessive: 1\n",
      "painstaking: 1\n",
      "isolate: 1\n",
      "toddler: 1\n",
      "girly: 1\n",
      "pissant: 1\n",
      "legitimate: 1\n",
      "mock: 1\n",
      "dedicate: 1\n",
      "receiver: 1\n",
      "punishable: 1\n",
      "restraint: 1\n",
      "corridor: 1\n",
      "consensual: 1\n",
      "penmanship: 1\n",
      "illegible: 1\n",
      "citation: 1\n",
      "progeny: 1\n",
      "fraudulently: 1\n",
      "worthless: 1\n",
      "landowner: 1\n",
      "deceit: 1\n",
      "solvent: 1\n",
      "unhealed: 1\n",
      "notebook: 1\n",
      "marital: 1\n",
      "watcher: 1\n",
      "breakthrough: 1\n",
      "hostile: 1\n",
      "reliable: 1\n",
      "sissy: 1\n",
      "habitat: 1\n",
      "cranberry: 1\n",
      "whatsoever: 1\n",
      "recessive: 1\n",
      "medic: 1\n",
      "truthful: 1\n",
      "fleck: 1\n",
      "tastefully: 1\n",
      "garnish: 1\n",
      "fiber: 1\n",
      "vulnerable: 1\n",
      "swat: 1\n",
      "disable: 1\n",
      "remotely: 1\n",
      "distributor: 1\n",
      "condolence: 1\n",
      "imperative: 1\n",
      "logically: 1\n",
      "commotion: 1\n",
      "amputation: 1\n",
      "distinctive: 1\n",
      "gulf: 1\n",
      "resurface: 1\n",
      "bulletin: 1\n",
      "dumpy: 1\n",
      "complect: 1\n",
      "fester: 1\n",
      "enlightenment: 1\n",
      "porcelain: 1\n",
      "psychologist: 1\n",
      "bagpipe: 1\n",
      "contradiction: 1\n",
      "improvise: 1\n",
      "admirably: 1\n",
      "weary: 1\n",
      "reflexive: 1\n",
      "oblige: 1\n",
      "enslavement: 1\n",
      "tireless: 1\n",
      "foliage: 1\n",
      "anesthesia: 1\n",
      "dignify: 1\n",
      "stoic: 1\n",
      "launder: 1\n",
      "backer: 1\n",
      "denounce: 1\n",
      "accusation: 1\n",
      "rectify: 1\n",
      "pacifist: 1\n",
      "repercussion: 1\n",
      "obnoxious: 1\n",
      "pimp: 1\n",
      "soiree: 1\n",
      "entrapment: 1\n",
      "horizon: 1\n",
      "premonition: 1\n",
      "mystic: 1\n",
      "gullible: 1\n",
      "correspondingly: 1\n",
      "outweigh: 1\n",
      "philander: 1\n",
      "vengeance: 1\n",
      "frantic: 1\n",
      "infallible: 1\n",
      "cuss: 1\n",
      "daze: 1\n",
      "dazzle: 1\n",
      "humdrum: 1\n",
      "conglomerate: 1\n",
      "assignment: 1\n",
      "inconvenience: 1\n",
      "befriend: 1\n",
      "convene: 1\n",
      "flippant: 1\n",
      "compulsion: 1\n",
      "hallucinate: 1\n",
      "prod: 1\n",
      "coronation: 1\n",
      "sideline: 1\n",
      "wench: 1\n",
      "dwell: 1\n",
      "paranoia: 1\n",
      "immersive: 1\n",
      "persecute: 1\n",
      "dutch: 1\n",
      "brushwork: 1\n",
      "cocktail: 1\n",
      "shareholder: 1\n",
      "defuse: 1\n",
      "heroine: 1\n",
      "brunette: 1\n",
      "tremor: 1\n",
      "spar: 1\n",
      "adversary: 1\n",
      "jugular: 1\n",
      "reckless: 1\n",
      "scrub: 1\n",
      "phony: 1\n",
      "dunk: 1\n",
      "imprison: 1\n",
      "assign: 1\n",
      "spade: 1\n",
      "tuck: 1\n",
      "taker: 1\n",
      "seize: 1\n",
      "feedback: 1\n",
      "biological: 1\n",
      "peach: 1\n",
      "antagonize: 1\n",
      "poorly: 1\n",
      "retreat: 1\n",
      "chasten: 1\n",
      "checkmate: 1\n",
      "drool: 1\n",
      "sterling: 1\n",
      "heirloom: 1\n",
      "patty: 1\n",
      "technically: 1\n",
      "emblem: 1\n",
      "ambivalent: 1\n",
      "rake: 1\n",
      "homer: 1\n",
      "goose: 1\n",
      "crummy: 1\n",
      "multiplex: 1\n",
      "checkbook: 1\n",
      "adulation: 1\n",
      "bucket: 1\n",
      "poker: 1\n",
      "reliever: 1\n",
      "dishevel: 1\n",
      "tactful: 1\n",
      "expel: 1\n",
      "jock: 1\n",
      "prosecute: 1\n",
      "blackjack: 1\n",
      "rebellion: 1\n",
      "ulcer: 1\n",
      "clarinet: 1\n",
      "whereabouts: 1\n",
      "bassoon: 1\n",
      "whirlwind: 1\n",
      "dampen: 1\n",
      "mullet: 1\n",
      "glean: 1\n",
      "cargo: 1\n",
      "therapeutic: 1\n",
      "overdose: 1\n",
      "archive: 1\n",
      "plaster: 1\n",
      "yank: 1\n",
      "warp: 1\n",
      "dame: 1\n",
      "airfield: 1\n",
      "discrepancy: 1\n",
      "shill: 1\n",
      "presidential: 1\n",
      "discourage: 1\n",
      "roil: 1\n",
      "unavenged: 1\n",
      "insufferable: 1\n",
      "tattered: 1\n",
      "shrug: 1\n",
      "readily: 1\n",
      "alumnus: 1\n",
      "greet: 1\n",
      "realtor: 1\n",
      "dubious: 1\n",
      "stickler: 1\n",
      "pledge: 1\n",
      "flier: 1\n",
      "timpani: 1\n",
      "stump: 1\n",
      "commence: 1\n",
      "initiate: 1\n",
      "brutalize: 1\n",
      "helpless: 1\n",
      "stitch: 1\n",
      "debater: 1\n",
      "hierarchy: 1\n",
      "empower: 1\n",
      "poetic: 1\n",
      "vanity: 1\n",
      "spine: 1\n",
      "pathetic: 1\n",
      "reminder: 1\n",
      "charade: 1\n",
      "afar: 1\n",
      "trumpet: 1\n",
      "chay: 1\n",
      "summit: 1\n",
      "telegraph: 1\n",
      "grandma: 1\n",
      "soothe: 1\n",
      "dealership: 1\n",
      "chump: 1\n",
      "groove: 1\n",
      "infantile: 1\n",
      "persistent: 1\n",
      "turnover: 1\n",
      "evidentiary: 1\n",
      "procedural: 1\n",
      "laceration: 1\n",
      "invasion: 1\n",
      "hostage: 1\n",
      "creek: 1\n",
      "equity: 1\n",
      "complexity: 1\n",
      "interaction: 1\n",
      "embrace: 1\n",
      "loosen: 1\n",
      "unreliable: 1\n",
      "eagerly: 1\n",
      "renaissance: 1\n",
      "knuckle: 1\n",
      "wade: 1\n",
      "interloper: 1\n",
      "porch: 1\n",
      "immerse: 1\n",
      "weave: 1\n",
      "linen: 1\n",
      "descendant: 1\n",
      "apparition: 1\n",
      "groan: 1\n",
      "footprint: 1\n",
      "storage: 1\n",
      "specialize: 1\n",
      "fecklessness: 1\n",
      "incapable: 1\n",
      "lien: 1\n",
      "escrow: 1\n",
      "historian: 1\n",
      "spiritualism: 1\n",
      "deceitful: 1\n",
      "exterior: 1\n",
      "credulous: 1\n",
      "mastery: 1\n",
      "occult: 1\n",
      "prohibition: 1\n",
      "cellar: 1\n",
      "evasion: 1\n",
      "psychiatric: 1\n",
      "ruckus: 1\n",
      "furious: 1\n",
      "uninhabitable: 1\n",
      "sentimental: 1\n",
      "furtive: 1\n",
      "boast: 1\n",
      "loot: 1\n",
      "unveil: 1\n",
      "smidge: 1\n",
      "sausage: 1\n",
      "detain: 1\n",
      "whodunit: 1\n",
      "musky: 1\n",
      "phallic: 1\n",
      "cougar: 1\n",
      "moderate: 1\n",
      "lantern: 1\n",
      "versus: 1\n",
      "decoy: 1\n",
      "lull: 1\n",
      "directional: 1\n",
      "smirk: 1\n",
      "misconduct: 1\n",
      "lurch: 1\n",
      "responder: 1\n",
      "suffocate: 1\n",
      "paraphernalia: 1\n",
      "remission: 1\n",
      "kraut: 1\n",
      "confinement: 1\n",
      "blunt: 1\n",
      "riverbank: 1\n",
      "connive: 1\n",
      "humble: 1\n",
      "culpa: 1\n",
      "vendor: 1\n",
      "amend: 1\n",
      "despise: 1\n",
      "deposition: 1\n",
      "triply: 1\n",
      "burglary: 1\n",
      "willful: 1\n",
      "dangle: 1\n",
      "bait: 1\n",
      "copper: 1\n",
      "grisly: 1\n",
      "duplex: 1\n",
      "monthly: 1\n",
      "fiction: 1\n",
      "swap: 1\n",
      "compromise: 1\n",
      "witty: 1\n",
      "flack: 1\n",
      "nicotine: 1\n",
      "unironed: 1\n",
      "positivity: 1\n",
      "crucify: 1\n",
      "concur: 1\n",
      "brewster: 1\n",
      "folksy: 1\n",
      "flunky: 1\n",
      "scuffle: 1\n",
      "topaz: 1\n",
      "birthstone: 1\n",
      "exclamation: 1\n",
      "toast: 1\n",
      "liaison: 1\n",
      "junket: 1\n",
      "madman: 1\n",
      "abomination: 1\n",
      "raze: 1\n",
      "ecosystem: 1\n",
      "purloin: 1\n",
      "outlying: 1\n",
      "hurdle: 1\n",
      "outrageous: 1\n",
      "slander: 1\n",
      "incompetent: 1\n",
      "rookie: 1\n",
      "vantage: 1\n",
      "acolyte: 1\n",
      "hindsight: 1\n",
      "intrusive: 1\n",
      "neurosis: 1\n",
      "incite: 1\n",
      "riot: 1\n",
      "proclaim: 1\n",
      "figuratively: 1\n",
      "avenge: 1\n",
      "sierra: 1\n",
      "foothill: 1\n",
      "recovery: 1\n",
      "cunningly: 1\n",
      "taunt: 1\n",
      "revelation: 1\n",
      "accuser: 1\n",
      "bizarre: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir_path = \"/home/arshad/Downloads/mentalist_sub/\"\n",
    "word_count={}\n",
    "for file_name in os.listdir(dir_path):\n",
    "    # check if the file is a .srt file\n",
    "    if file_name.endswith(\".srt\"):\n",
    "        print(f\"Processing {os.path.join(dir_path, file_name)}\")\n",
    "        word_lst = gettext(os.path.join(dir_path, file_name))\n",
    "        getFinalList1(word_lst,word_count=word_count)\n",
    "\n",
    "\n",
    "sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "print(f\"Word count: {len(sorted_words)}\")\n",
    "\n",
    "for word, count in sorted_words:\n",
    "    print(f\"{word}: {count}\")   \n",
    "    #print(f\"{word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35518479-a7bf-4c92-9e49-2ee5cad8f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
